# Kafka란
> 네이버 DEVIEW 2023 [네이버 스케일로 카프카 컨슈머 사용하기](https://www.youtube.com/watch?v=OxMdru93E6k) 세션을 보고 정리한 내용입니다.


<img src = https://user-images.githubusercontent.com/102847513/230760829-8f6cfb83-816c-4d89-8d84-20a1a8668ef6.png width = 50% height = 50%>


# Kafka란?

간단하게 말해서, **Log 자료구조를 분산 스토리지 형태로 만든 것**

- Log란 **레코드를 추가된 순서로 저장**하는 자료구조
    - 쓴 순서대로 저장하고 저장된 순서대로 읽는 것이 특징
    - 레코드란 무엇인가?
        
        로그 자료구조에서 **레코드는 로그 파일에 기록된 개별적인 이벤트를** 나타냄
        
        - 로그는 시스템, 응용 프로그램 또는 네트워크에서 발생하는 다양한 이벤트를 기록하는 데 사용
        - 이벤트는 일반적으로 시간, 날짜, 이벤트 유형 및 관련 데이터와 함께 기록
- 카프카는 Log 자료구조에 **Topic**이라는 이름을 붙여 관리

### 일반 Log 자료구조와 카프카의 차이

카프카에서 사용하는 것은 **분할되고 복제된** 로그

- 전체 레코드를 한 개 이상의 파티션으로 나뉘어 저장하고 각 파티션을 한 개 이상의 replica로 복제하여 복제
- 나뉘어 저장하기 때문에 전체 읽기든 쓰기든 하나의 서버(브로커)에 몰리는 일이 X
    - **고가용성**의 달성
- 다만, 순서 보장의 기능이 약해짐
    - 기본적인 로그 안에서는 모든 레코드의 순서 보장이 당연하지만
    - 카프카에서는 단일 파티션 안에서만 순서가 보장

## 카프카 구조

- 각 파티션을 한 개 이상의 **레플리카로 복제하여 저장**되기 때문에
    - 한 레플리카가 fail 되더라도 전체 작업이 fail 하는 일이 X
    - 이때 한 개 이상의 복제된 레플리카에서 한 개만 리더가 되고 **나머지는 follower**가 됨
- 카프카에서는 **3개의 클라이언트**가 존재
    - 쓸 때 사용하는 클라이언트 → **Producer**
    - 읽을 때 사용하는 클라이언트 → **Consumer**
    - ~~다른 하나 → 토픽 생성, 설정 변경 등을 하는 Admin~~

### 프로듀서와 컨슈머

- 프로듀서
    - 레코드 사용시 자기가 사용하고 싶다면 어느 파티션에나 레코드를 추가 가능
    - **프로듀서 간의 협력이 필요 X**
        - 두 개 이상의 스레드가 함께 사용해도 상관 X
        - 고로, 프로듀서 객체는 Thread safe
- 컨슈머
    - 하나의 파티션은 반드시 하나의 컨슈머에 의해서만 읽혀지기 가능 → 독점적
    - 왜?
        - 파티션 안에서 **순서가 보장되는 것이 가장 중요**하기 때문에
        - 하나의 파티션을 두 개이상의 컨슈머가 읽는다면 순서가 뒤바뀔 수 있음
    - **컨슈머 간의 협력을 통해** 두 개 이상의 컨슈머가 하나의 파티션을 읽는 일이 발생하면 X
        - 두 개 이상의 스레드가 함께 사용할 필요가 없음
        - 고로, 컨슈머 객체는 Thread safe X

# Consumer Group

컨슈머들의 가장 큰 특성 → **협력**

### Consumer Group이란?

<img src = https://user-images.githubusercontent.com/102847513/230760943-cd29eb72-234d-43b6-b234-24a8f1b224c3.png width = 60% height = 60%>


- **여러개의 컨슈머 중에서 같은 ‘group.id’ 설정값을 가진 Consumer들은 하나의 Consumer Group을 이룸**
- 같은 컨슈머 그룹에 속한 컨슈머들이 토픽에 속한 파티션들을 나눠서 읽음

### 중요한 것 : 리밸런스(Rebalance)

- 파티션 수나 컨슈머 수의 **변화를 자동으로 처리함**으로써 읽기 작업을 **완전히 추상화**
    - 용량이 부족하다 싶으면 파티션 수를 늘리거나 작업하던 컨슈머가 모종의 이유로 죽는다는 등등의 경우에도 완전히 자동으로 컨슈머 그룹이 처리

### 결과적으로 컨슈머 그룹은

- 하나의 토픽에 저장된 레코드 전체를 읽어들이는 논리적인 환상 또는 논리적인 컨슈머의 개념
- 물리적인 컨슈머들 간의 협력을 자동으로 처리함

## Consumer Group에 필요한 것은?

### 1. Partition Assignment 기능

구독하고자 하는 파티션들을 현재 파티션의 집합에 중복도 누락도 없이 할당해주는 할당 매커니즘

### 2. Offset Commit 기능

리밸런스가 발생했을 때 특정 파티션에 대한 정보들(작업 재개, 누락 등)을 저장하는 저장 매커니즘

## Consumer Coordination 동작원리

Partition Assignment에서 어떻게 할당을 해줄까? → ~~서버쪽에서?~~ NO

<img src = https://user-images.githubusercontent.com/102847513/230761144-0c273de5-86ee-41bd-8ab5-ffe5657b210c.png width = 60% height = 60%>

- 컨슈머 그룹에서는 하나의 컨슈머가 그룹 리더가 됨
    - 파티션들을 컨슈머에 할당을 해주는 것이 컨슈머 그룹 리더
- 컨슈머들끼리는 직접적인 커뮤니케이션 X
- 같은 컨슈머 그룹에 속한 컨슈머들은 **Consumer Group Coordination을 통해서 통신!!!!**

### 리밸런싱의 상세 과정

- 실제 할당 작업을 수행하는 것은 **Consumer Group Coordination이므로 할당 후**
- 정보를 모아 Consumer Group Leader에게 전달
- 전달받은 정보를 Consumer Group Leader는 각 Consumer들에게 전달

### 왜 위와 같은 복잡한 구조?

- 브로커를 재시작할 필요없이 더 **유연하고 확장 가능한 파티션 할당**을 지원하기 위해
    - 브로커에 할당 매커니즘을 맡기면
    - 할당 매커니즘의 변경 시 브로커를 재시작해야 되게 됨
    - 확장 가능성 ⬇️

## Partition.assignment.strategy의 원리

- 유연성있게 파티션을 할당하기 위한 컨슈머 설정의 기본값!

```java
partition.assignment.strategy = [
	org.apache.kafka.clients.consumer.RangeAssignor.class, // 앞에 있으므로 우선순위가 높음
	org.apache.kafka.clients.consumer.CooperativeStickyAssignor.class 
]
```

1. Consumer Group에 참여한 **모든 Consumer에 공통으로 설정된 Assignor** 중에서
2. 우선순위가 가장 높은 것(목록 중 앞에 있는 것)이 **파티션 할당 전략으로 선택**
- 단순히 내가 원하는 할당 알고리즘을 정의하는 것을 넘어
- 내가 필요로 하는 커스텀 데이터를 프로토콜 안에 사용자 영역으로 보낼/받을 수 있음

**→ 매우 높은 유연성**

<img src = https://user-images.githubusercontent.com/102847513/230761181-a0728738-c391-42ef-b0b4-4e193eed9f39.png width = 60% height = 60%>

### 예시 : RangeAssignor

- 컨슈머 그룹이 두 개의 토픽을 구독
- 각 토픽 별로 속한 파티션들을 라운드 로빈 방식으로 할당
    - 0번 컨슈머는 4개, 1번과 2번 파티션은 각각 2개의 파티션을 할당